{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJ1ZYycQbOHrqmuxbSVkbh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ppujari/PyTorch/blob/main/PyTorch_tips.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dEjIW3Moc9_"
      },
      "outputs": [],
      "source": [
        "# prompt: pytorch tips\n",
        "\n",
        "# Use `torch.cuda.is_available()` to check if CUDA is available before using it.\n",
        "# This can help avoid errors and improve performance.\n",
        "\n",
        "# Use `torch.no_grad()` context manager to disable gradient computation when it is not needed.\n",
        "# This can save memory and improve performance.\n",
        "\n",
        "# Use `torch.jit.trace()` to create a traced version of your model for improved performance.\n",
        "# This can be especially useful for models that are used frequently.\n",
        "\n",
        "# Use `torch.utils.data.DataLoader` to load your data in batches.\n",
        "# This can help improve performance by reducing the number of times the data is loaded into memory.\n",
        "\n",
        "# Use `torch.optim.lr_scheduler` to adjust the learning rate during training.\n",
        "# This can help improve the convergence of the model.\n",
        "\n",
        "# Use `torch.nn.utils.clip_grad_norm_` to clip the gradients during training.\n",
        "# This can help prevent the gradients from becoming too large and causing the model to diverge.\n",
        "\n",
        "# Use `torch.utils.tensorboard` to visualize the training process.\n",
        "# This can help you track the progress of the model and identify any potential problems.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch Tip - 3\n"
      ],
      "metadata": {
        "id": "uh9hzytOo3BH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using torch.where() for Conditional Element-wise Operations**\n",
        "PyTorch's **torch.where()** function allows you to perform conditional element-wise operations efficiently. It takes three arguments: the condition, the tensor to select values from when the condition is true, and the tensor to select values from when the condition is false. This is particularly useful for implementing conditional logic within your neural network models.\n",
        "\n",
        "Here's a quick example:\n",
        "In this example, the elements from tensor_true are selected where the condition is True, and elements from tensor_false are selected where the condition is False. This allows for flexible conditional operations within your PyTorch code."
      ],
      "metadata": {
        "id": "Jcg0XpAApdau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define tensors\n",
        "condition = torch.tensor([[True, False], [False, True]])\n",
        "tensor_true = torch.tensor([[1, 2], [3, 4]])\n",
        "tensor_false = torch.tensor([[5, 6], [7, 8]])\n",
        "\n",
        "# Perform conditional element-wise operation\n",
        "result = torch.where(condition, tensor_true, tensor_false)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7mRti28pMqD",
        "outputId": "97194fd7-0b82-49ac-802c-65f798555847"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 6],\n",
            "        [7, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some Practical usages below:**"
      ],
      "metadata": {
        "id": "qzSlhc4ivTZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Masked Operations:** You might have a tensor and want to perform different operations on elements based on some condition. For instance, in natural language processing, you might want to mask out certain tokens during tokenization or in attention mechanisms based on some condition."
      ],
      "metadata": {
        "id": "UvnyYYzhttJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Example: Masking tokens with a special token ID\n",
        "input_ids = torch.tensor([101, 102, 103, 104, 105])  # Example input tensor\n",
        "mask_condition = input_ids == 103  # Condition to mask out token with ID 103\n",
        "special_token_id = 1000  # Special token ID to replace masked tokens\n",
        "\n",
        "# Mask out tokens with ID 103\n",
        "masked_input_ids = torch.where(mask_condition, torch.tensor(special_token_id), input_ids)\n",
        "\n",
        "print(masked_input_ids)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMQbnWpgueW5",
        "outputId": "7e6c055e-76a9-486e-ff96-83e9c1093f0d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 101,  102, 1000,  104,  105])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Loss Function Modification:** During training, you may want to apply different weights to different elements of the loss function based on some condition."
      ],
      "metadata": {
        "id": "LftkpiTduzQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Example: Modifying loss function based on class imbalance\n",
        "predicted_scores = torch.tensor([0.1, 0.8, 0.3, 0.9, 0.2])  # Example predicted scores\n",
        "true_labels = torch.tensor([0, 1, 0, 1, 1])  # Example true labels\n",
        "\n",
        "# Calculate binary cross-entropy loss with class imbalance handling\n",
        "positive_weight = 2.0  # Weight for positive class\n",
        "negative_weight = 1.0  # Weight for negative class\n",
        "loss_weights = torch.where(true_labels == 1, positive_weight, negative_weight)\n",
        "\n",
        "# Calculate weighted binary cross-entropy loss\n",
        "loss = F.binary_cross_entropy_with_logits(predicted_scores, true_labels.float(), weight=loss_weights)\n",
        "\n",
        "print(loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJLbatNqu_dE",
        "outputId": "8ec03f28-e114-4380-d1c8-99bba95ce2a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8439)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Interpretability:** In some scenarios, you might want to interpret the output of your model differently based on certain conditions."
      ],
      "metadata": {
        "id": "9Kravs2713ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Example: Interpreting model output differently based on confidence\n",
        "output_scores = torch.tensor([0.8, 0.6, 0.9, 0.4, 0.7])  # Example output scores\n",
        "confidence_threshold = 0.7  # Threshold for high confidence\n",
        "\n",
        "# Determine model predictions based on confidence\n",
        "predictions = torch.where(output_scores >= confidence_threshold, torch.tensor(1), torch.tensor(0))\n",
        "\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awdjw-uq16Ft",
        "outputId": "11c76eff-e294-48ba-b359-5de12a4422b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 0, 1, 0, 1])\n"
          ]
        }
      ]
    }
  ]
}